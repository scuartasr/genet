{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVLYVoQvQ0Rm"
      },
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td style=\"text-align:left\">\n",
        "            <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR9ItLTT_F-3Q30cu7ZCCoKmuFGBt22pe7pNA\" alt=\"Logo Universidad\" width=\"300\"/>\n",
        "        </td>\n",
        "        <td>\n",
        "            Departamento de Ciencias de la Computación y de la Decisión<br>\n",
        "            Facultad de Minas<br>\n",
        "            Universidad Nacional de Colombia<br>\n",
        "            Optimizacion e IA 2024-2S<br><br>\n",
        "            Docente: Maria Constanza Torres Madronero<br>\n",
        "            <br>\n",
        "            Contribuciones a la guia por: <br>\n",
        "            - Deimer Miranda Montoya (2023)<br>\n",
        "            - Luis Fernando Becerra Monsalve (2024)\n",
        "        </td>    \n",
        "        </td>    \n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización de funciones\n",
        "\n",
        "Vamos a comparar el desempeño de los optimizadores gradiente descendente, algoritmo genético, enjambre de partículas y colonia de hormigas. Para ello usaremos una función no convexa con la cual trabajamos en la Practica 1.\n"
      ],
      "metadata": {
        "id": "nE6ea-MbYcFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm"
      ],
      "metadata": {
        "id": "nGKSyUWcyx_e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Minimizacion de una funcion 2D\n",
        "#f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2\n",
        "def objective_func(solution):\n",
        "  term1 = (solution[0]**2+solution[1]-11)**2\n",
        "  term2 = (solution[0]+solution[1]**2-7)**2\n",
        "  return term1+term2\n",
        "\n",
        "#Grafica de la funcion\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "y = np.linspace(-5, 5, 1000)\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "feval = objective_func([xv,yv])\n",
        "ax = plt.figure().add_subplot(111,projection='3d')\n",
        "ax.plot_surface(xv, yv, feval, cmap=cm.jet)"
      ],
      "metadata": {
        "id": "u1SyrkCSaanj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradiente descendiente"
      ],
      "metadata": {
        "id": "h2LgYTjv0Qpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion que evalua el gradiente en un punto solucion\n",
        "def derivative(X):\n",
        "  x = X[0]\n",
        "  y = X[1]\n",
        "  term0 = 4*x**3+4*x*y-42*x+2*y**2-14\n",
        "  term1 = 2*x**2+4*x*y+4*y**3-26*y-22\n",
        "  gradiente = np.array([term0,term1])\n",
        "  return gradiente"
      ],
      "metadata": {
        "id": "yQ-tcsWz0UEo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion del gradiente descendente\n",
        "def gradient_descent(objective_func, derivative, bounds, n_iter, step_size):\n",
        "  # Generamos el punto inicial de forma aleatoria\n",
        "  solution0 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution1 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution = np.array([solution0,solution1])\n",
        "\t# Algoritmo iterativo\n",
        "  for i in range(n_iter):\n",
        "\t\t#1. Calculo del gradiente\n",
        "    gradiente = derivative(solution)\n",
        "\t\t#2. Actualizacion de la solucion\n",
        "    solution = solution - step_size*gradiente\n",
        "  \t#3. Evaluacion de la solucion\n",
        "    solution_eval = objective_func(solution)\n",
        "    #print('>%d f(%s) = %.5f' % (i, solution, solution_eval))\n",
        "  return solution"
      ],
      "metadata": {
        "id": "3t-4pA1c1p4b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicacion del gradiente\n",
        "bounds = np.asarray([[-4.0, 4.0]])\n",
        "n_iter = 500\n",
        "step_size = 0.01\n",
        "solution = gradient_descent(objective_func, derivative, bounds, n_iter, step_size)\n",
        "#Guardamos la solucion para la comparacion\n",
        "xopGD, yopGD = solution\n",
        "fevalGD = objective_func(solution)\n",
        "\n",
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopGD, yopGD,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ],
      "metadata": {
        "id": "BBiGTzt62oA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmos Geneticos"
      ],
      "metadata": {
        "id": "NqhBE2Tu7eEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygad"
      ],
      "metadata": {
        "id": "IAA9VYavtVtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar libreria pygad\n",
        "import pygad"
      ],
      "metadata": {
        "id": "jM9S-pdn7bJ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paso 1: Definire funcion fitness (funcion de aptitud)\n",
        "def fitness_func(ga_instance, solution, solution_idx):\n",
        "    #Llamamos nuestra funcion objetivo\n",
        "    output = objective_func(solution)\n",
        "    #Calculamos el fitness (Convertimos el problema de minimizacion a maximizacion)\n",
        "    fitness = 1/(output+0.0001)\n",
        "    return fitness"
      ],
      "metadata": {
        "id": "FS8Nl47V8nUx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paso 2: Preparamos los parametros para correr el algoritmo genetico\n",
        "num_generations = 500\n",
        "num_parents_mating = 6\n",
        "fitness_function = fitness_func\n",
        "sol_per_pop = 20\n",
        "num_genes = 2\n",
        "init_range_low = -4\n",
        "init_range_high = 4\n",
        "parent_selection_type = \"tournament\"\n",
        "keep_parents = 3\n",
        "crossover_type = \"single_point\"\n",
        "crossover_probability=0.4\n",
        "mutation_type = \"random\"\n",
        "mutation_probability = 0.1"
      ],
      "metadata": {
        "id": "6kvpzsat799M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciar el Algoritmo\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       fitness_func=fitness_function,\n",
        "                       sol_per_pop=sol_per_pop,\n",
        "                       num_genes=num_genes,\n",
        "                       init_range_low=init_range_low,\n",
        "                       init_range_high=init_range_high,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       keep_parents=keep_parents,\n",
        "                       crossover_type=crossover_type,\n",
        "                       crossover_probability = crossover_probability,\n",
        "                       mutation_type=mutation_type,\n",
        "                       mutation_probability=mutation_probability)"
      ],
      "metadata": {
        "id": "3QMrGShK8e5L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corremos el algoritmo\n",
        "ga_instance.run()\n",
        "\n",
        "#Extraemos la mejor solucion\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(f\"Parameters of the best solution : {solution}\")\n",
        "print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
        "\n",
        "prediction = objective_func(solution)\n",
        "print(f\"Valor optimo para la funcion: = {prediction}\")\n",
        "\n",
        "#Guardamos la solucion para la comparacion\n",
        "xopAG, yopAG = solution\n",
        "fevalAG = prediction\n",
        "\n",
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopAG, yopAG,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ],
      "metadata": {
        "id": "6a3HmTnu89xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PSO: Optimizacion por enjambre de particulas\n",
        "Para el algoritmo de PSO vamos a usar la libreria PySwarms. Similar a algoritmos geneticos, vamos a encontrar varias librerias con la implementacion de este algoritmo. Para conocer un poco mas de esta libreria pueden consultar el siguiente enlaceÑ [PySwarms](https://pyswarms.readthedocs.io/en/latest/)."
      ],
      "metadata": {
        "id": "EPFZf6vVufCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalamos la libreria\n"
      ],
      "metadata": {
        "id": "R-4RhAPOuPnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la libreria\n"
      ],
      "metadata": {
        "id": "fqHmnLVRud5a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definicmos los hiperparametros\n",
        "#c1: importancia a la experiencia propia\n",
        "#c2: importancia de la experiencia del lider del enjambre\n",
        "#w: momentum o coeficiente en la direccion de busqueda\n",
        "\n",
        "#Valores max y min iniciales para las particulas\n",
        "\n",
        "#Instanciacion del optimizador\n"
      ],
      "metadata": {
        "id": "wB5SS5Q8vCvH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste de la funcion objetivo\n",
        "#f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2\n",
        "def objective_func2(solution):\n",
        "#####\n",
        "  return term1+term2"
      ],
      "metadata": {
        "id": "GfzlZQK4wfWl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corremos el algoritmo PSO\n"
      ],
      "metadata": {
        "id": "UUnO7Yi6wLiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraemos la mejor solucion\n",
        "\n",
        "print(f\"Parameters of the best solution : {solution}\")\n",
        "\n",
        "prediction = objective_func(solution)\n",
        "print(f\"Valor optimo para la funcion: = {prediction}\")\n",
        "\n",
        "#Guardamos la solucion para la comparacion\n",
        "xopPSO, yopPSO = solution\n",
        "fevalPSO = prediction"
      ],
      "metadata": {
        "id": "me5TBgVxxBf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopAG, yopAG,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ],
      "metadata": {
        "id": "ZLHKyqTPxcuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos graficar la funcion de costo en terminos de las iteraciones\n",
        "from pyswarms.utils.plotters import (plot_cost_history, plot_contour, plot_surface)\n",
        "plot_cost_history(cost_history=optimizer.cost_history)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tNhu31cRwryC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}