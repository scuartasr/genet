{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVLYVoQvQ0Rm"
      },
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td style=\"text-align:left\">\n",
        "            <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR9ItLTT_F-3Q30cu7ZCCoKmuFGBt22pe7pNA\" alt=\"Logo Universidad\" width=\"300\"/>\n",
        "        </td>\n",
        "        <td>\n",
        "            Departamento de Ciencias de la Computación y de la Decisión<br>\n",
        "            Facultad de Minas<br>\n",
        "            Universidad Nacional de Colombia<br>\n",
        "            Optimizacion e IA 2024-2S<br><br>\n",
        "            Docente: Maria Constanza Torres Madronero<br>\n",
        "            <br>\n",
        "            Contribuciones a la guia por: <br>\n",
        "            - Deimer Miranda Montoya (2023)<br>\n",
        "            - Luis Fernando Becerra Monsalve (2024)\n",
        "        </td>    \n",
        "        </td>    \n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización de funciones\n",
        "\n",
        "Vamos a comparar el desempeño de los optimizadores gradiente descendente, algoritmo genético, enjambre de partículas y colonia de hormigas. Para ello usaremos una función no convexa con la cual trabajamos en la Practica 1.\n"
      ],
      "metadata": {
        "id": "nE6ea-MbYcFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm"
      ],
      "metadata": {
        "id": "nGKSyUWcyx_e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Minimizacion de una funcion 2D\n",
        "#f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2\n"
      ],
      "metadata": {
        "id": "u1SyrkCSaanj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafica de la funcion\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "y = np.linspace(-5, 5, 1000)\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "feval = objective_func([xv,yv])\n",
        "ax = plt.figure().add_subplot(111,projection='3d')\n",
        "ax.plot_surface(xv, yv, feval, cmap=cm.jet)"
      ],
      "metadata": {
        "id": "7kVMffYrcghO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradiente descendiente"
      ],
      "metadata": {
        "id": "h2LgYTjv0Qpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos el método del gradiente descendiente:\n",
        "1. Necesitamos conocer la primera derivada de la función objetivo: el gradiente. Para nuestro ejemplo, dado que tenemos una función en dos dimensiones, el gradiente será un vector con dos componentes.\n"
      ],
      "metadata": {
        "id": "7I_6-DffZLpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion que evalua el gradiente en un punto solucion\n",
        "def derivative(X):\n",
        "  x = X[0]\n",
        "  y = X[1]\n",
        "  term0 = 4*x**3+4*x*y-42*x+2*y**2-14\n",
        "  term1 = 2*x**2+4*x*y+4*y**3-26*y-22\n",
        "  gradiente = np.array([term0,term1])\n",
        "  return gradiente"
      ],
      "metadata": {
        "id": "yQ-tcsWz0UEo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. El algoritmo iterativo: cada iteración proporciona una posible solución de la función de optimización. El punto inicial lo seleccionamos de forma aleatoria, y lo actualizamos en cada iteración restando el gradiente escalado con el paso de aprendizaje."
      ],
      "metadata": {
        "id": "PEr8Us1-Zw0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion del gradiente descendente\n",
        "def gradient_descent(objective_func, derivative, bounds, n_iter, step_size):\n",
        "  # Generamos el punto inicial de forma aleatoria\n",
        "  solution0 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution1 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution = np.array([solution0,solution1])\n",
        "\t# Algoritmo iterativo\n",
        "  for i in range(n_iter):\n",
        "\t\t#1. Calculo del gradiente\n",
        "\n",
        "\t\t#2. Actualizacion de la solucion\n",
        "\n",
        "    #3. Evaluacion de la solucion\n",
        "\n",
        "    #print('>%d f(%s) = %.5f' % (i, solution, solution_eval))\n",
        "  return solution"
      ],
      "metadata": {
        "id": "3t-4pA1c1p4b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deliminatos el rango de los datos\n",
        "\n",
        "# Definimos el numero de iteraciones\n",
        "\n",
        "# Seleccionamos la longitud del paso\n",
        "\n",
        "# Aplicamos el algoritmo de gradiente descendente\n",
        "\n",
        "#Guardamos la solucion para la comparacion\n"
      ],
      "metadata": {
        "id": "BBiGTzt62oA1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopGD, yopGD,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ],
      "metadata": {
        "id": "LY-kOwmP6FmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo Genético\n",
        "Existen diversas librerías con la implementación de los métodos metaheurísticos. Dado que es un área de desarrollo, es difícil encontrar librerías que integren una alta variedad de métodos y que permitan fácilmente su comparación.\n",
        "\n",
        "En este practica usaremos primero la libreria PyGAD para aplicar el metodo basado en algoritmos geneticos para la minimizacion de nuestra funcion objetivo.\n",
        "\n",
        "PyGAD implementa los algoritmo geneticos, puede ser combinado con algoritmos de aprendizaje de maquina, trabaja con Keras y Pytorch.\n",
        "\n",
        "En el siguiente enlace pueden conocer un poco mas de esta libreria: [PyGAD](https://pygad.readthedocs.io/en/latest/index.html).\n",
        "\n",
        "Estas librerías deben instalarse en el entorno de ejecución!!!"
      ],
      "metadata": {
        "id": "2mQHipPA6TtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalacion de la libreria\n"
      ],
      "metadata": {
        "id": "NqhBE2Tu7eEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar libreria pygad\n"
      ],
      "metadata": {
        "id": "jM9S-pdn7bJ2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paso 1: Definire funcion fitness (funcion de aptitud)\n",
        "#Uno de los parametros para entrenar el algoritmo genetico es la funcion fitness,\n",
        "#la cual debe ser definida por el usuario. Esta funcion debe ser una funcion de\n",
        "#maximizacion, de tal forma que el valor mas alto de aptitud sera retornado.\n",
        "#La funcion puede retornar un unico valor o un arreglo. Esta funcion debe tener\n",
        "#tres parametros de entrada.\n",
        "#Parametro 1: La instancia de la clase GA\n",
        "#Parametro 2: La(s) solucion(s) para calcular la funcion fitness\n",
        "#Parametro 3: Los indices de la solucion en la poblacion\n",
        "\n",
        "def fitness_func(ga_instance, solution, solution_idx):\n",
        "    #Llamamos nuestra funcion objetivo\n",
        "\n",
        "    #Calculamos el fitness (Convertimos el problema de minimizacion a maximizacion)\n",
        "\n",
        "    return fitness"
      ],
      "metadata": {
        "id": "FS8Nl47V8nUx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paso 2: Preparamos los parametros para correr el algoritmo genetico\n",
        "#Numero de generaciones\n",
        "\n",
        "#Numero de soluciones a ser seleccionads como padres\n",
        "\n",
        "#Establecer la funcion fitness\n",
        "\n",
        "#Numero de soluciones por poblacion\n",
        "\n",
        "#Numero de genes en la solucion\n",
        "#Por defecto se establecen flotantes, pero se puede modificar int, uint\n",
        "\n",
        "#Rangos iniciales para la poblacion inicial\n",
        "\n",
        "#Metodo para la seleccion de padres\n",
        "#\"rws\": Ruleta\n",
        "#\"tournament\": Torneo\n",
        "\n",
        "#Numero de padres a mantener en la poblacion\n",
        "\n",
        "#Tipo de cruce: en un solo punto, dos puntos, uniforme\n",
        "\n",
        "#Probabilidad para realizar el cruze\n",
        "\n",
        "#Tipo de mutacion\n",
        "\n",
        "#Probabilidad de mutacion\n"
      ],
      "metadata": {
        "id": "6kvpzsat799M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciar el Algoritmo\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       fitness_func=fitness_function,\n",
        "                       sol_per_pop=sol_per_pop,\n",
        "                       num_genes=num_genes,\n",
        "                       init_range_low=init_range_low,\n",
        "                       init_range_high=init_range_high,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       keep_parents=keep_parents,\n",
        "                       crossover_type=crossover_type,\n",
        "                       crossover_probability = crossover_probability,\n",
        "                       mutation_type=mutation_type,\n",
        "                       mutation_probability=mutation_probability)"
      ],
      "metadata": {
        "id": "3QMrGShK8e5L"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corremos el algoritmo\n"
      ],
      "metadata": {
        "id": "6a3HmTnu89xn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraemos la mejor solucion\n",
        "\n",
        "##\n",
        "print(f\"Parameters of the best solution : {solution}\")\n",
        "print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
        "##\n",
        "print(f\"Valor optimo para la funcion: = {prediction}\")\n",
        "\n",
        "#Guardamos la solucion para la comparacion\n",
        "\n"
      ],
      "metadata": {
        "id": "vYLMfW289CA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficar el avance"
      ],
      "metadata": {
        "id": "88d3mmx5Irx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopAG, yopAG,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ],
      "metadata": {
        "id": "OI15DrULuWDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}