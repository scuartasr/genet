{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVLYVoQvQ0Rm"
      },
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td style=\"text-align:left\">\n",
        "            <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR9ItLTT_F-3Q30cu7ZCCoKmuFGBt22pe7pNA\" alt=\"Logo Universidad\" width=\"300\"/>\n",
        "        </td>\n",
        "        <td>\n",
        "            Departamento de Ciencias de la Computación y de la Decisión<br>\n",
        "            Facultad de Minas<br>\n",
        "            Universidad Nacional de Colombia<br>\n",
        "            Optimizacion e IA 2024-2S<br><br>\n",
        "            Docente: Maria Constanza Torres Madronero<br>\n",
        "            <br>\n",
        "            Contribuciones a la guia por: <br>\n",
        "            - Deimer Miranda Montoya (2023)<br>\n",
        "            - Luis Fernando Becerra Monsalve (2024)\n",
        "        </td>    \n",
        "        </td>    \n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE6ea-MbYcFW"
      },
      "source": [
        "### Optimización de funciones\n",
        "\n",
        "Vamos a comparar el desempeño de los optimizadores gradiente descendente, algoritmo genético, enjambre de partículas y colonia de hormigas. Para ello usaremos una función no convexa con la cual trabajamos en la Practica 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGKSyUWcyx_e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1SyrkCSaanj"
      },
      "outputs": [],
      "source": [
        "#Minimizacion de una funcion 2D\n",
        "#f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2\n",
        "def objective_func(solution):\n",
        "    term1 = (solution[0]**2 + solution[1] - 11)**2\n",
        "    term2 = (solution[0] + solution[1]**2 - 7)**2\n",
        "    return term1+term2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kVMffYrcghO"
      },
      "outputs": [],
      "source": [
        "#Grafica de la funcion\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "y = np.linspace(-5, 5, 1000)\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "feval = objective_func([xv,yv])\n",
        "ax = plt.figure().add_subplot(111,projection='3d')\n",
        "ax.plot_surface(xv, yv, feval, cmap=cm.jet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2LgYTjv0Qpp"
      },
      "source": [
        "### Gradiente descendiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I_6-DffZLpx"
      },
      "source": [
        "Recordemos el método del gradiente descendiente:\n",
        "1. Necesitamos conocer la primera derivada de la función objetivo: el gradiente. Para nuestro ejemplo, dado que tenemos una función en dos dimensiones, el gradiente será un vector con dos componentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ-tcsWz0UEo"
      },
      "outputs": [],
      "source": [
        "#Funcion que evalua el gradiente en un punto solucion\n",
        "def derivative(X):\n",
        "  x = X[0]\n",
        "  y = X[1]\n",
        "  term0 = 4*x**3+4*x*y-42*x+2*y**2-14\n",
        "  term1 = 2*x**2+4*x*y+4*y**3-26*y-22\n",
        "  gradiente = np.array([term0,term1])\n",
        "  return gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEr8Us1-Zw0h"
      },
      "source": [
        "2. El algoritmo iterativo: cada iteración proporciona una posible solución de la función de optimización. El punto inicial lo seleccionamos de forma aleatoria, y lo actualizamos en cada iteración restando el gradiente escalado con el paso de aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t-4pA1c1p4b"
      },
      "outputs": [],
      "source": [
        "#Funcion del gradiente descendente\n",
        "def gradient_descent(objective_func, derivative, bounds, n_iter, step_size):\n",
        "  # Generamos el punto inicial de forma aleatoria\n",
        "  solution0 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution1 = bounds[:,0]+rand(len(bounds))*(bounds[:,1]-bounds[:,0])\n",
        "  solution = np.array([solution0,solution1])\n",
        "\t# Algoritmo iterativo\n",
        "  for i in range(n_iter):\n",
        "\t\t#1. Calculo del gradiente\n",
        "    gradiente = derivative(solution)\n",
        "\t\t#2. Actualizacion de la solucion\n",
        "    solution = solution - step_size * gradiente\n",
        "    #3. Evaluacion de la solucion\n",
        "    solution_eval = objective_func(solution)\n",
        "    #print('>%d f(%s) = %.5f' % (i, solution, solution_eval))\n",
        "  return solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBiGTzt62oA1"
      },
      "outputs": [],
      "source": [
        "# Deliminatos el rango de los datos\n",
        "bounds = np.array([[-4.0, 4.0, ]])\n",
        "# Definimos el numero de iteraciones\n",
        "n_iter = 500\n",
        "# Seleccionamos la longitud del paso\n",
        "step_size = 0.01\n",
        "# Aplicamos el algoritmo de gradiente descendente\n",
        "solution = gradient_descent(objective_func, derivative, bounds, n_iter, step_size)\n",
        "#Guardamos la solucion para la comparacion\n",
        "xopGD, yopGD = solution\n",
        "fevalGD = objective_func(solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY-kOwmP6FmG"
      },
      "outputs": [],
      "source": [
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopGD, yopGD,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mQHipPA6TtP"
      },
      "source": [
        "### Algoritmo Genético\n",
        "Existen diversas librerías con la implementación de los métodos metaheurísticos. Dado que es un área de desarrollo, es difícil encontrar librerías que integren una alta variedad de métodos y que permitan fácilmente su comparación.\n",
        "\n",
        "En este practica usaremos primero la libreria PyGAD para aplicar el metodo basado en algoritmos geneticos para la minimizacion de nuestra funcion objetivo.\n",
        "\n",
        "PyGAD implementa los algoritmo geneticos, puede ser combinado con algoritmos de aprendizaje de maquina, trabaja con Keras y Pytorch.\n",
        "\n",
        "En el siguiente enlace pueden conocer un poco mas de esta libreria: [PyGAD](https://pygad.readthedocs.io/en/latest/index.html).\n",
        "\n",
        "Estas librerías deben instalarse en el entorno de ejecución!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqhBE2Tu7eEO"
      },
      "outputs": [],
      "source": [
        "#Instalacion de la libreria\n",
        "!pip install pygad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM9S-pdn7bJ2"
      },
      "outputs": [],
      "source": [
        "#Importar libreria pygad\n",
        "import pygad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Paso 1.** *Definir funcion fitness (funcion de aptitud).* Uno de los parámetros para entrenar el algoritmo genático es la función *fitness,* la cual debe ser definida por el usuario. Esta función debe ser una función de maximización, de tal forma que el valor más alto de aptitud sera retornado. La función puede retornar un unico valor o un arreglo. Esta función debe tener tres parámetros de entrada.\n",
        "- *Parámetro 1.* La instancia de la clase GA\n",
        "- *Parámetro 2.* La(s) solución(s) para calcular la función fitness\n",
        "- *Parámetro 3.* Los índices de la solución en la población"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS8Nl47V8nUx"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Conversión del problema de minimización en uno de maximización\n",
        "\n",
        "def fitness_func(ga_instance, solution, solution_idx):\n",
        "    #Llamamos nuestra funcion objetivo\n",
        "    output = objective_func(solution)\n",
        "    #Calculamos el fitness (Convertimos el problema de minimizacion a maximizacion)\n",
        "    fitness = 1.0/(output+1e4)\n",
        "    return fitness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Paso 2**. Preparamos los parámetros para correr el algoritmo genético."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kvpzsat799M"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Número de generaciones\n",
        "num_generations = 500\n",
        "\n",
        "# Número de soluciones a ser seleccionads como padres\n",
        "num_parents_mating = 6\n",
        "\n",
        "# Establecer la función fitness\n",
        "fitness_function = fitness_func\n",
        "\n",
        "# Número de soluciones por población\n",
        "sol_per_pop  = 20\n",
        "\n",
        "# Número de genes en la solución\n",
        "# --> Por defecto, se establecen flotantes, pero se puede modificar int, uint\n",
        "num_genes = 2\n",
        "\n",
        "# Rangos iniciales para la población inicial\n",
        "init_range_low = -4\n",
        "init_range_high = 4\n",
        "\n",
        "# Método para la seleccion de padres\n",
        "# \"rws\": Ruleta\n",
        "# \"tournament\": Torneo\n",
        "parent_selection_type = 'tournament'\n",
        "\n",
        "# Número de padres a mantener en la población\n",
        "keep_parents = 3\n",
        "\n",
        "# Tipo de cruce: en un solo punto, dos puntos, uniforme\n",
        "crossover_type = 'single_point'\n",
        "\n",
        "# Probabilidad para realizar el cruze\n",
        "crossover_probability = 0.3\n",
        "\n",
        "# Tipo de mutación\n",
        "mutation_type = 'random'\n",
        "\n",
        "# Probabilidad de mutación\n",
        "mutation_probability = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QMrGShK8e5L"
      },
      "outputs": [],
      "source": [
        "#Instanciar el Algoritmo\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       fitness_func=fitness_function,\n",
        "                       sol_per_pop=sol_per_pop,\n",
        "                       num_genes=num_genes,\n",
        "                       init_range_low=init_range_low,\n",
        "                       init_range_high=init_range_high,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       keep_parents=keep_parents,\n",
        "                       crossover_type=crossover_type,\n",
        "                       crossover_probability = crossover_probability,\n",
        "                       mutation_type=mutation_type,\n",
        "                       mutation_probability=mutation_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Paso 3.** Ejecución del algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a3HmTnu89xn"
      },
      "outputs": [],
      "source": [
        "#Corremos el algoritmo\n",
        "ga_instance.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Paso 4.** Extracción de la mejor solución"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYLMfW289CA3"
      },
      "outputs": [],
      "source": [
        "# Extraemos la mejor solución\n",
        "solution, solution_fitness, solution_inx = ga_instance.best_solution()\n",
        "\n",
        "##\n",
        "print(f\"Parameters of the best solution : {solution}\")\n",
        "print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
        "##\n",
        "prediction = objective_func(solution)\n",
        "print(f\"Valor optimo para la funcion: = {prediction}\")\n",
        "\n",
        "# Guardamos la solucion para la comparacion\n",
        "xopAG, yopAG = solution\n",
        "fevalAG = objective_func(solution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88d3mmx5Irx_"
      },
      "outputs": [],
      "source": [
        "# Graficar el avance\n",
        "ga_instance.plot_fitness()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI15DrULuWDp"
      },
      "outputs": [],
      "source": [
        "#Grafica de los contornos y punto optimo\n",
        "plt.contourf(xv, yv, feval, levels=50, cmap='jet')\n",
        "plt.scatter(xopAG, yopAG,c='white',marker='o')\n",
        "plt.colorbar()\n",
        "print(fevalGD)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
